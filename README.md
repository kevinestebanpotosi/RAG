# ğŸ§  Azure Hybrid RAG System (Cost-Optimized)

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![Azure](https://img.shields.io/badge/Azure-AI%20Search-0078D4)
![Groq](https://img.shields.io/badge/Groq-LPU-orange)
![Status](https://img.shields.io/badge/Status-Production%20Ready-green)

Un sistema de **GeneraciÃ³n Aumentada por RecuperaciÃ³n (RAG)** de nivel empresarial diseÃ±ado con arquitectura hÃ­brida para optimizar costos de cÃ³mputo sin sacrificar rendimiento.

**CaracterÃ­sticas clave:**
- ğŸ¯ Procesamiento local de documentos PDF (Edge Computing)
- ğŸš€ Embeddings generados localmente (no requiere API)
- â˜ï¸ Almacenamiento vectorial escalable en Azure AI Search
- ğŸ’¬ Chat interactivo impulsado por Groq LPU (Llama 3.3 70B)
- ğŸ’° Arquitectura cost-optimized (Ãºnicamente paga por inferencia)

---

## ğŸ“ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Ingestion Pipeline                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  PDF Files  â†’  PyPDF2  â†’  Text Chunking  â†’  Sentence-  â†’   â”‚
â”‚               Parser       (500 chars,         Trans-        â”‚
â”‚                           50 overlap)         formers        â”‚
â”‚                                               (Local)        â”‚
â”‚                                                 â†“             â”‚
â”‚                                            384D Vectors      â”‚
â”‚                                                 â†“             â”‚
â”‚                                         Azure AI Search      â”‚
â”‚                                         (Indexing HNSW)      â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Chat Pipeline                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  User Query  â†’  Local Embedding  â†’  Vector Search  â†’  Top-K â”‚
â”‚                                      (Azure Search)   Docs   â”‚
â”‚                                                        â†“      â”‚
â”‚                                       Context Building â†“     â”‚
â”‚                                       (Format Prompt) â†“      â”‚
â”‚                                                        â†“      â”‚
â”‚   â† Response â† Groq API (Llama-3.3-70B) â† LLM Call         â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ ConfiguraciÃ³n RÃ¡pida

### Prerrequisitos
- Python 3.10 o superior
- Cuenta Azure con AI Search habilitado
- API Key de Groq (https://console.groq.com)

### 1ï¸âƒ£ InstalaciÃ³n

```bash
# Clonar repositorio
git clone <your-repo-url>
cd RAG
```

```bash
# Crear entorno virtual
python -m venv venv

# Activar entorno
# En Windows:
venv\Scripts\activate
# En macOS/Linux:
source venv/bin/activate
```

```bash
# Instalar dependencias
pip install -r requirements.txt
```

### 2ï¸âƒ£ ConfiguraciÃ³n de Variables de Entorno

Crear archivo `.env` en la raÃ­z del proyecto:

```env
# Azure AI Search
AZURE_SEARCH_ENDPOINT=https://your-resource.search.windows.net
AZURE_SEARCH_KEY=your-admin-key

# Groq LPU
GROQ_API_KEY=gsk_your_api_key
```

**CÃ³mo obtener las credenciales:**
- **Azure:** Portal Azure â†’ AI Search â†’ Keys â†’ Copiar endpoint y admin key
- **Groq:** https://console.groq.com â†’ API Keys â†’ Create New Key

### 3ï¸âƒ£ Ejecutar la AplicaciÃ³n

```bash
python main.py
```

Selecciona una opciÃ³n:
```
Select Mode: [1] Ingest PDF, [2] Chat: 
```

---

## ğŸ“– Uso

### Modo 1: IngestiÃ³n de PDFs

```
Select Mode: [1] Ingest PDF, [2] Chat: 1
Enter PDF path (e.g., data/manual.pdf): data/documento.pdf
```

**QuÃ© sucede:**
1. Lee el PDF y extrae texto
2. Divide el contenido en chunks de 500 caracteres (overlap de 50)
3. Genera embeddings localmente usando Sentence-Transformers
4. Sube los vectors a Azure AI Search con metadatos

### Modo 2: Chat RAG

```
Select Mode: [1] Ingest PDF, [2] Chat: 2
--- Chat Started (type 'exit' to quit) ---

User: Â¿CuÃ¡l es el objetivo principal del documento?
Bot: [Respuesta generada usando el contexto del documento]
Sources: {'documento.pdf'}
```

---

## ğŸ—ï¸ Estructura del Proyecto

```
RAG/
â”œâ”€â”€ main.py                 # Punto de entrada (CLI interactiva)
â”œâ”€â”€ requirements.txt        # Dependencias del proyecto
â”œâ”€â”€ .env.example           # Template de variables de entorno
â”œâ”€â”€ .gitignore            # Archivos ignorados en git
â”œâ”€â”€ README.md             # Este archivo
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py         # ConfiguraciÃ³n centralizada
â”‚   â”œâ”€â”€ ingestion.py      # Pipeline de ingesta de PDFs
â”‚   â””â”€â”€ rag_engine.py     # Motor de RAG (retrieval + generation)
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ *.pdf             # PDFs para procesar (no se suben a git)
â”‚
â”œâ”€â”€ notebooks/            # Jupyter notebooks para experimentaciÃ³n
â”‚   â””â”€â”€ (anÃ¡lisis y pruebas)
â”‚
â””â”€â”€ venv/                 # Entorno virtual (no se sube a git)
```

---

## ğŸ“¦ Dependencias Principales

| Paquete | VersiÃ³n | PropÃ³sito |
|---------|---------|-----------|
| `azure-search-documents` | â‰¥11.4.0 | Cliente de Azure AI Search |
| `groq` | â‰¥0.5.0 | API de Groq para inferencia |
| `sentence-transformers` | â‰¥2.2.0 | GeneraciÃ³n de embeddings locales |
| `pypdf` | â‰¥4.0.0 | ExtracciÃ³n de texto de PDFs |
| `torch` | â‰¥2.0.0 | Dependencia de transformers |
| `python-dotenv` | â‰¥1.0.0 | GestiÃ³n de variables de entorno |

---

## âš™ï¸ ConfiguraciÃ³n Avanzada

### ParÃ¡metros Ajustables (src/config.py)

```python
CHUNK_SIZE = 500           # TamaÃ±o de cada chunk en caracteres
CHUNK_OVERLAP = 50         # SuperposiciÃ³n entre chunks
EMBEDDING_MODEL = "all-MiniLM-L6-v2"  # Modelo de embeddings
CHAT_MODEL = "llama-3.3-70b-versatile"  # Modelo LLM
INDEX_NAME = "portfolio-rag-index"     # Nombre del Ã­ndice en Azure
```

### Modelos Alternativos de Embeddings

Para mejor rendimiento, puedes cambiar el modelo:

```python
# MÃ¡s rÃ¡pido, menos preciso
EMBEDDING_MODEL = "all-MiniLM-L6-v2"  # 384D

# Mejor precisiÃ³n
EMBEDDING_MODEL = "all-mpnet-base-v2"  # 768D

# MÃ¡xima precisiÃ³n (requiere mÃ¡s VRAM)
EMBEDDING_MODEL = "all-roberta-large-v1"  # 1024D
```

---

## ğŸ” Troubleshooting

### Error: "âŒ Faltan variables de entorno en .env"
**SoluciÃ³n:** Verifica que tu archivo `.env` contenga las tres variables requeridas:
```bash
cat .env  # En bash/PowerShell
```

### Error: "Connection to Azure Search failed"
**SoluciÃ³n:** Verifica que:
- La URL de endpoint sea correcta (incluya `https://`)
- Tu API key sea vÃ¡lida
- Tu recurso Azure AI Search estÃ© activo

### Error: "Rate limit exceeded (429)" de Groq
**SoluciÃ³n:** El sistema estÃ¡ intentando demasiadas consultas. Espera unos minutos o reduce la frecuencia de consultas.

### Tiempo de carga lento en primer uso
**Nota:** La primera ejecuciÃ³n descarga modelos de Sentence-Transformers (~800MB). Es normal que tarde 2-3 minutos.

---

## ğŸ” Seguridad

- âœ… Archivo `.env` incluido en `.gitignore` (no se sube a git)
- âœ… PDFs grandes se procesan localmente (no se envÃ­an a Azure)
- âœ… Solo se almacenan vectores embeddings y chunks en Azure (sin datos sensibles crudos)
- âœ… Nunca hardcodees credenciales en el cÃ³digo

---

## ğŸ“ˆ EstimaciÃ³n de Costos (Azure)

| OperaciÃ³n | Costo Estimado | Notas |
|-----------|----------------|-------|
| Almacenamiento (1GB vectors) | ~$8-15/mes | AI Search (Standard tier) |
| Consultas de bÃºsqueda | Incluido | Ilimitadas en tier usado |
| Embeddings locales | $0 | Se generan en tu mÃ¡quina |
| Inferencia (Groq) | ~$0.001 por 1K tokens | Facturable directo con Groq |

**Comparativa sin arquitectura hÃ­brida:** Azure OpenAI embeddings costarÃ­a $0.02-0.10 por 1K tokens.

---

## ğŸ¤ Contribuciones

Las contribuciones son bienvenidas. Para cambios significativos:

1. Fork el repositorio
2. Crea una rama (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

---

## ğŸ“œ Licencia

Este proyecto estÃ¡ bajo la licencia MIT. Ver archivo `LICENSE` para mÃ¡s detalles.

---

## ğŸ™‹ Soporte

Â¿Preguntas o problemas? Abre un **Issue** en el repositorio.

---

**Ãšltima actualizaciÃ³n:** Diciembre 2025 | **VersiÃ³n:** 1.0.0

---

## ğŸ“ Arquitectura del Sistema

El sistema sigue un diseÃ±o desacoplado para maximizar la eficiencia:

```mermaid
graph LR
    A[Documentos PDF] -->|Ingesta Local| B(PyPDF & Chunking)
    B -->|Embedding Model| C{CPU Local}
    C -->|Vectores R^384| D[Azure AI Search]
    E[Usuario] -->|Query| C
    D -->|Retrieval Top-K| F[Contexto]
    F -->|Prompt| G[Groq LPU]
    G -->|Llama-3 GeneraciÃ³n| E